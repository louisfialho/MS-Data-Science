{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from numpy import array\n",
    "from numpy import random\n",
    "\n",
    "import math  \n",
    "import pandas as pd\n",
    "\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "\n",
    "# EXERCICE 1\n",
    "# Not done\n",
    "\n",
    "# EXERCICE 2\n",
    "# Double check results\n",
    "# Refactor using functions\n",
    "\n",
    "# EXERCICE 3\n",
    "# refactorer pr n'avoir qu'une fonction qui donne iter_u iter_v: plot les 2 sur même graphe?\n",
    "# Question 8 not found\n",
    "# Bonus questions not done\n",
    "# can you show it mathematically:\n",
    "# https://www.cs.yale.edu/homes/el327/datamining2013aFiles/07_singular_value_decomposition.pdf\n",
    "# https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/book-chapter-4.pdf\n",
    "\n",
    "# EXERCICE 5\n",
    "# split cat and num columns, create 2 pipelines (one for cat and one for num), \n",
    "# using a preprocessor like in this article \n",
    "# https://medium.com/@oluwabukunmige/implementing-linear-regression-with-sci-kit-learn-b6f87edc3150\n",
    "\n",
    "# VIF Factor above 10 indicates multicollinearity. cyclinders has highesht VIF factor.\n",
    "# Ridge regression (+ CV?)\n",
    "# Lasso regression\n",
    "# https://medium.com/analytics-vidhya/multiple-linear-regression-7727a012ff93\n",
    "# https://medium.com/@powusu381/multiple-regression-in-python-using-scikit-learn-predicting-the-miles-per-gallon-mpg-of-cars-4c8e512234be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Choose three non-Gaussian probability distributions, with mean 0 and variance 2, and\n",
    "write a function that that takes as input n, p and the distribution name, and creates a\n",
    "matrix X P R nˆp with entries generated (i.i.d.) according to this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 non-Gaussian probability distribution with mean 0 and var 2 we choose are <br>\n",
    "A uniform distribution over [-sqrt(6), sqrt(6)] (with sqrt(6) ~ 2.45) <br>\n",
    "A Laplace distribution with mean mu=0 and b=1 <br>\n",
    "A Logistic distribution with mean mu=0 and s=sqrt(6)/pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Display on one single graph the singular values of X for n “ 1000, and p “\n",
    "200, 500, 1000, 2000 for the three distributions chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(n, p, distribution):\n",
    "    if distribution == \"uniform\":\n",
    "        return np.random.uniform(-math.sqrt(6), math.sqrt(6), (n, p))\n",
    "    elif distribution == \"laplace\":\n",
    "        return np.random.laplace(0, 1, (n, p))\n",
    "    elif distribution == \"logistic\":\n",
    "        return np.random.logistic(0, math.sqrt(6)/math.pi, (n,p))\n",
    "    else:\n",
    "        return \"Choose distribution in 'uniform', 'laplace', or 'logistic'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = generator(1000, 200, \"uniform\")\n",
    "X2 = generator(1000, 500, \"uniform\")\n",
    "X3 = generator(1000, 1000, \"uniform\")\n",
    "X4 = generator(1000, 2000, \"uniform\")\n",
    "\n",
    "S1 = np.linalg.svd(X[1], compute_uv = False)\n",
    "S2 = np.linalg.svd(X[2], compute_uv = False)\n",
    "S3 = np.linalg.svd(X[3], compute_uv = False)\n",
    "S4 = np.linalg.svd(X[4], compute_uv = False)\n",
    "\n",
    "plt.plot(S1, label = \"p=200\")\n",
    "plt.plot(S2, label = \"p=500\")\n",
    "plt.plot(S3, label = \"p=1000\")\n",
    "plt.plot(S4, label = \"p=2000\")\n",
    "plt.xlabel('Singular value index')\n",
    "plt.ylabel('Singular value value')\n",
    "plt.title('Singular values of X, matrix of M1000,p, distributed uniformly with mean 0 and variance 2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = generator(1000, 200, \"laplace\")\n",
    "Y2 = generator(1000, 500, \"laplace\")\n",
    "Y3 = generator(1000, 1000, \"laplace\")\n",
    "Y4 = generator(1000, 2000, \"laplace\")\n",
    "\n",
    "S1 = np.linalg.svd(Y1, compute_uv = False)\n",
    "S2 = np.linalg.svd(Y2, compute_uv = False)\n",
    "S3 = np.linalg.svd(Y3, compute_uv = False)\n",
    "S4 = np.linalg.svd(Y4, compute_uv = False)\n",
    "\n",
    "plt.plot(S1, label = \"p=200\")\n",
    "plt.plot(S2, label = \"p=500\")\n",
    "plt.plot(S3, label = \"p=1000\")\n",
    "plt.plot(S4, label = \"p=2000\")\n",
    "plt.xlabel('Singular value index')\n",
    "plt.ylabel('Singular value value')\n",
    "plt.title('Singular values of Y, matrix of M1000,p, distributed by a Laplace law with mean 0 and variance 2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = generator(1000, 200, \"logistic\")\n",
    "Z2 = generator(1000, 500, \"logistic\")\n",
    "Z3 = generator(1000, 1000, \"logistic\")\n",
    "Z4 = generator(1000, 2000, \"logistic\")\n",
    "\n",
    "S1 = np.linalg.svd(Z1, compute_uv = False)\n",
    "S2 = np.linalg.svd(Z2, compute_uv = False)\n",
    "S3 = np.linalg.svd(Z3, compute_uv = False)\n",
    "S4 = np.linalg.svd(Z4, compute_uv = False)\n",
    "\n",
    "plt.plot(S1, label = \"p=200\")\n",
    "plt.plot(S2, label = \"p=500\")\n",
    "plt.plot(S3, label = \"p=1000\")\n",
    "plt.plot(S4, label = \"p=2000\")\n",
    "plt.xlabel('Singular value index')\n",
    "plt.ylabel('Singular value value')\n",
    "plt.title('Singular values of Z, matrix of M1000,p, distributed by a Logistic law with mean 0 and variance 2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Display on one single graph the spectrum (i.e. the set of eigen values) of XJX{n for\n",
    "n “ 1000, and p “ 200, 500, 1000, 2000. Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "X1_prime = X1.T @ X1 / n\n",
    "X2_prime = X2.T @ X2 / n\n",
    "X3_prime = X3.T @ X3 / n\n",
    "X4_prime = X4.T @ X4 / n\n",
    "\n",
    "# Getting the vectors of eigen values (sorted in desc order) \n",
    "W1 = LA.eig(X1_prime)[0]\n",
    "W1[::-1].sort()\n",
    "W2 = LA.eig(X2_prime)[0]\n",
    "W2[::-1].sort()\n",
    "W3 = LA.eig(X3_prime)[0]\n",
    "W3[::-1].sort()\n",
    "W4 = LA.eig(X4_prime)[0]\n",
    "W4[::-1].sort()\n",
    "\n",
    "plt.plot(W1, label = \"p=200\")\n",
    "plt.plot(W2, label = \"p=500\")\n",
    "plt.plot(W3, label = \"p=1000\")\n",
    "plt.plot(W4, label = \"p=2000\")\n",
    "plt.title(\"Eigenvalues of X.T@X/n of Mp(R), where X is distributed with a uniform of mean 0 and variance 2\")\n",
    "plt.xlabel(\"Eigenvalue index\")\n",
    "plt.ylabel(\"Eigenvalue value\")\n",
    "plt.xlim(0, 1000)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_prime = Y1.T @ Y1 / n\n",
    "Y2_prime = Y2.T @ Y2 / n\n",
    "Y3_prime = Y3.T @ Y3 / n\n",
    "Y4_prime = Y4.T @ Y4 / n\n",
    "\n",
    "# Get the vectors of eigen values (sorted in desc order) W1, W2, W3, W4\n",
    "W1 = LA.eig(Y1_prime)[0]\n",
    "W1[::-1].sort()\n",
    "W2 = LA.eig(Y2_prime)[0]\n",
    "W2[::-1].sort()\n",
    "W3 = LA.eig(Y3_prime)[0]\n",
    "W3[::-1].sort()\n",
    "W4 = LA.eig(Y4_prime)[0]\n",
    "W4[::-1].sort()\n",
    "\n",
    "plt.plot(W1, label = \"p=200\")\n",
    "plt.plot(W2, label = \"p=500\")\n",
    "plt.plot(W3, label = \"p=1000\")\n",
    "plt.plot(W4, label = \"p=2000\")\n",
    "plt.title(\"Eigenvalues of X.T@X/n of Mp(R), where X is distributed with a Laplace of mean 0 and variance 2\")\n",
    "plt.xlabel(\"Eigenvalue index\")\n",
    "plt.ylabel(\"Eigenvalue value\")\n",
    "plt.xlim(0, 1000)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1_prime = Z1.T @ Z1 / n\n",
    "Z2_prime = Z2.T @ Z2 / n\n",
    "Z3_prime = Z3.T @ Z3 / n\n",
    "Z4_prime = Z4.T @ Z4 / n\n",
    "\n",
    "# Get the vectors of eigen values (sorted in desc order) W1, W2, W3, W4\n",
    "W1 = LA.eig(Z1_prime)[0]\n",
    "W1[::-1].sort()\n",
    "W2 = LA.eig(Z2_prime)[0]\n",
    "W2[::-1].sort()\n",
    "W3 = LA.eig(Z3_prime)[0]\n",
    "W3[::-1].sort()\n",
    "W4 = LA.eig(Z4_prime)[0]\n",
    "W4[::-1].sort()\n",
    "# Plot\n",
    "plt.plot(W1, label = \"p=200\")\n",
    "plt.plot(W2, label = \"p=500\")\n",
    "plt.plot(W3, label = \"p=1000\")\n",
    "plt.plot(W4, label = \"p=2000\")\n",
    "plt.title(\"Eigenvalues of X.T@X/n of Mp(R), where X is distributed with a Logistic law of mean 0 and variance 2\")\n",
    "plt.xlabel(\"Eigenvalue index\")\n",
    "plt.ylabel(\"Eigenvalue value\")\n",
    "plt.xlim(0, 1000)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments <br>\n",
    "<br>\n",
    "X matrix of M1000,p is distributed with a uniform probability and has mean 0 and var 2 <br>\n",
    "Y matrix of M1000,p is distributed with a Laplace probability and has mean 0 and var 2 <br>\n",
    "Z matrix of M1000,p is distributed with a logistic probability and has mean 0 and var 2 <br>\n",
    "<br>\n",
    "We create X1, X2, X3, X4 by fixing n=1000 and increasing p (from 200, 500, 1000 and 2000).<br>\n",
    "We create Y1, Y2, Y3, Y4 by fixing n=1000 and increasing p (from 200, 500, 1000 and 2000).<br>\n",
    "We create Z1, Z2, Z3, Z4 by fixing n=1000 and increasing p (from 200, 500, 1000 and 2000).<br>\n",
    "<br>\n",
    "In the first question, we plot the singular values of Xi, Yi, Zi for various values of p. <br>\n",
    "I.E. we plot the sqrts of the eigen values of Xi.T @ Xi, Yi.T @ Yi, Zi.T @ Zi. <br>\n",
    "For all 3 distributions, we get the same plot: <br>\n",
    "-The # of non negative singular values = the # of columns. <br>\n",
    "-The values of those singluar values have greater amplitude (higher maximum, lower minimum) as p increases <br>\n",
    "-The singular values decrease in a linear fashion <br>\n",
    "<br>\n",
    "In the second question, we plot the eigenvalues of Xi.T @ Xi / n, Yi.T @ Yi / n, Zi.T @ Zi / n, where n=1000 <br>\n",
    "I.E. we plot the eigevalues * 1/n of Xi.T @ Xi, Yi.T @ Yi, Zi.T @ Zi.  <br>\n",
    "For all 3 distributions, we get the same plot.  <br>\n",
    "-The # of non negative eigen values = the # of columns. <br>\n",
    "-The values of those eigen values have greater maximum as p increases, and all tend to reach 0 <br>\n",
    "-The singular values decrease in a quadratic fashion <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Write a function coding the power Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method(X, n, u, v):\n",
    "    for j in range(0, n):\n",
    "        u = X @ v \n",
    "        v = X.T @ u\n",
    "        v = v/LA.norm(v)\n",
    "        u = u/LA.norm(u)\n",
    "    return (u,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Illustrate visually (with a graph) the convergence of the algorithm iterates. Is it true that\n",
    "the output u, v from the algorithm converge to the singular vector associated to the largest\n",
    "singular value of X (check by computing these with numpy built in functions) ? Bonus :\n",
    "can you show it mathematically ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "n = 100\n",
    "p = 2000\n",
    "n_iter = 250\n",
    "\n",
    "X = np.random.normal(loc=0, scale=5, size=(n, p)) \n",
    "u = np.random.rand(n, 1) \n",
    "v = np.random.rand(p, 1)\n",
    "\n",
    "U, s, VT = svd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence of U\n",
    "\n",
    "# We create an array iter_u containing U for n_iter\n",
    "def iter_u(X, n, u, v):\n",
    "    iter_u = []\n",
    "    for j in range(0, n):\n",
    "        u = X @ v \n",
    "        v = X.T @ u\n",
    "        v = v/LA.norm(v)\n",
    "        u = u/LA.norm(u)\n",
    "        iter_u.append(u)\n",
    "    return(np.absolute(iter_u))\n",
    "\n",
    "iter_u = iter_u(X, n_iter, u, v)\n",
    "\n",
    "# We create an array limit_u containing the limit vector, \n",
    "# i.e. the left singular vector, for n_iter\n",
    "limit_u = U[:,0].reshape(n, 1)\n",
    "limit_u = np.full(shape=(n_iter, n, 1), fill_value=limit_u)\n",
    "limit_u = np.absolute(limit_u)\n",
    "\n",
    "# We substract the abs value of iter_u and the abs value of limit_u\n",
    "# and we compute the L2-norm\n",
    "conv_u = iter_u - limit_u\n",
    "norm_conv_u = LA.norm(conv_u, axis=1)\n",
    "\n",
    "# We plot n_iter and the L2-norm\n",
    "plt.plot(norm_conv_u)\n",
    "plt.title(\"Convergence of u to the left-singular vector of X\")\n",
    "plt.xlabel(\"Number of iterations of the power algorithm\")\n",
    "plt.ylabel(\"L2-Norm of u - u_limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence of V\n",
    "\n",
    "# We create an array iter_v containing V for n_iter\n",
    "def iter_v(X, n, u, v):\n",
    "    iter_v = []\n",
    "    for j in range(0, n):\n",
    "        u = X @ v \n",
    "        v = X.T @ u\n",
    "        v = v/LA.norm(v)\n",
    "        u = u/LA.norm(u)\n",
    "        iter_v.append(v)\n",
    "    return(np.absolute(iter_v))\n",
    "\n",
    "iter_v = iter_v(X, n_iter, u, v)\n",
    "\n",
    "# We create an array limit_v containing the limit vector, \n",
    "# i.e. the right singular vector, for n_iter \n",
    "limit_v = VT.transpose()[:,0].reshape(p,1)\n",
    "limit_v = np.full(shape=(n_iter, p,1), fill_value=limit_v)\n",
    "limit_v = np.absolute(limit_v)\n",
    "\n",
    "# We substract the abs value of iter_v and the abs value of limit_v\n",
    "# and we compute the L2-norm\n",
    "conv_v = iter_v - limit_v\n",
    "norm_conv_v = LA.norm(conv_v, axis=1)\n",
    "\n",
    "# # We plot n_iter and the L2-norm \n",
    "plt.plot(norm_conv_v)\n",
    "plt.title(\"Convergence of v to the right-singular vector of X\")\n",
    "plt.xlabel(\"Number of iterations of the power algorithm\")\n",
    "plt.ylabel(\"L2-Norm of v - v_limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Provide two sets of initialization vectors leading to different limits for this algorithm ;\n",
    "explain how they are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We tried to choose u, v orthogonal to the limit vectors but the convergence was still valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Provide a way to approximate the largest singular value of X using the power method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated a matrix X using a normal distribution <br>\n",
    "The power method approximates ui and vi, the left and right singular vectors of the largest singular value of X <br>\n",
    "We know that, if ui and vi are the left-singular vector and the right-singular vector associated with σi then, Avi=σiui and ATui=σivi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "n = 100\n",
    "p = 2000\n",
    "n_iter = 300 # The # of iterations is important to get a good approximation\n",
    "\n",
    "X = np.random.normal(loc=0, scale=5, size=(n, p)) \n",
    "u = np.random.rand(n, 1) \n",
    "v = np.random.rand(p, 1) \n",
    "\n",
    "u, v = power_method(X, n_iter, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First way to approximate \n",
    "sigma = (X @ v) / u\n",
    "print(sigma[0])\n",
    "\n",
    "# Second way to approximate \n",
    "sigma = (X.T @ u) / v\n",
    "print(sigma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the actual value of sigma through svd\n",
    "U, s, VT = svd(X)\n",
    "print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing approximation and actual value\n",
    "np.isclose(sigma[0], s[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB. On note que le nombre d'itérations n_iter doit être suffisamment élevé pour obtenir une approximation correcte\n",
    "Pour ce faire, on détermine n_iter en utilisant les représentations graphiques obtenu à la question 7. <br>\n",
    "Pour améliorer cet algorithme on chercherait à déterminer n automatiquement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Bonus : build upon the power method to provide an algorithm that can approximate the\n",
    "second largest singular value of X (without using an SVD function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 4. (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Import with Pandas the dataset defra_consumption.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://josephsalmon.eu/enseignement/TELECOM/SD204/defra_consumption.csv', sep=';')\n",
    "df.rename({'Unnamed: 0': 'Category'}, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Center and standardize the dataset using the preprocessing module from sklearn, where\n",
    "we write X P Rnˆp for the associated matrix (n “ 17 is the number of observations, and p “ 4 is the number of variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c in df.columns\n",
    "                     if df[c].dtype.kind in [\"i\", \"f\"]]\n",
    "\n",
    "df[num_cols] = preprocessing.scale(df[num_cols]) \n",
    "\n",
    "X = df.iloc[:,1:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Display a scatter plot of the n points projected on the space generated by the first two\n",
    "principal axes (corresponding to largest eigenvalues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing 2 or 3 dimensional data is not that challenging. \n",
    "However, our dataset is 4 dimensional. \n",
    "We will use PCA to reduce that 4 dimensional data into 2 or 3 dimensions so that we can plot and hopefully understand the data better. <br>\n",
    "In this section, the code projects the original data which is 4 dimensional into 2 dimensions. We note that after dimensionality reduction, there usually isn’t a particular meaning assigned to each principal component. The new components are just the two main dimensions of variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PC1', 'PC2'])\n",
    "pca_df = pd.concat([pca_df, df[['Category']]], axis = 1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", s=100)\n",
    "plt.xlabel(\"PC1\", fontsize = \"20\")\n",
    "plt.ylabel(\"PC2\", fontsize = \"20\")\n",
    "\n",
    "# Add labels : try using Adjusttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained variance tells how much information (variance) can be attributed to each of the principal components. <br>\n",
    "Here, we notice that, although the 2 compoents contain 99% of information together, the first component contains much more information that the second one (97% vs 2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Repeat the previous question for the space generated by three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "pca_df_2 = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_df_2['PC1'], pca_df_2['PC2'], pca_df_2['PC3'], s=70)\n",
    "\n",
    "plt.title(\"3 dimensions\")\n",
    "ax.view_init(15, 260)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Compare the previous 2D and 3D graphs with the one obtained as follows :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Compute X.T @ X, and diagonalize it. Project the n points encoded by X over the span\n",
    "of the eigen vectors associated to the two (respectively three) largest eigen values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dimensions\n",
    "\n",
    "start11 = time.time()\n",
    "\n",
    "eigen_values, eigen_vectors = LA.eig(X.T @ X)\n",
    "\n",
    "idx = eigen_values.argsort()[::-1]   \n",
    "eigen_values = eigen_values[idx]\n",
    "eigen_vectors = eigen_vectors[:,idx]\n",
    "\n",
    "P = np.array(eigen_vectors)\n",
    "M = X @ P[:, :2]\n",
    "pcomp = pd.DataFrame(data = M\n",
    "             , columns = ['PC1', 'PC2'])\n",
    "\n",
    "time11 = time.time() - start11\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=pcomp, x=\"PC1\", y=\"PC2\", s=100)\n",
    "plt.xlabel(\"PC1\", fontsize = \"20\")\n",
    "plt.ylabel(\"PC2\", fontsize = \"20\")\n",
    "sns.set(rc={'figure.figsize':(15,15)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 dimensions\n",
    "\n",
    "start12 = time.time()\n",
    "\n",
    "eigen_values, eigen_vectors = LA.eig(X.T @ X)\n",
    "\n",
    "idx = eigen_values.argsort()[::-1]   \n",
    "eigen_values = eigen_values[idx]\n",
    "eigen_vectors = eigen_vectors[:,idx]\n",
    "\n",
    "P = np.array(eigen_vectors)\n",
    "M = X @ P[:, :3]\n",
    "pcomp = pd.DataFrame(data = M\n",
    "                     , columns = ['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "time12 = time.time() - start12\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pcomp['PC1'], pcomp['PC2'], pcomp['PC3'], s=70)\n",
    "plt.title(\"3 dimensions\")\n",
    "ax.view_init(15, 260)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMELIORER CE GRAPH https://python-graph-gallery.com/372-3d-pca-result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Compute the SVD of X. Project the n points encoded by X P R\n",
    "nˆp over the span of\n",
    "the correct (right or left ?) singular vectors associated to the two (respectively three)\n",
    "largest singular values 2\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start21 = time.time()\n",
    "\n",
    "u, s, vh = np.linalg.svd(X, full_matrices=False)\n",
    "V = vh.T\n",
    "\n",
    "M = X @ V[:, :2]\n",
    "pcomp = pd.DataFrame(data = M\n",
    "             , columns = ['PC1', 'PC2'])\n",
    "\n",
    "time21 = time.time() - start21\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=pcomp, x=\"PC1\", y=\"PC2\", s=100)\n",
    "plt.xlabel(\"PC1\", fontsize = \"20\")\n",
    "plt.ylabel(\"PC2\", fontsize = \"20\")\n",
    "sns.set(rc={'figure.figsize':(15,15)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start22 = time.time()\n",
    "\n",
    "u, s, vh = np.linalg.svd(X, full_matrices=False)\n",
    "V = vh.T\n",
    "\n",
    "M = X @ V[:, :3]\n",
    "pcomp = pd.DataFrame(data = M\n",
    "                     , columns = ['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "time22 = time.time() - start22\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pcomp['PC1'], pcomp['PC2'], pcomp['PC3'], s=70)\n",
    "plt.title(\"3 dimensions\")\n",
    "ax.view_init(15, 260)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Evaluate the difference in timing for the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For dimension = 2, the time elapsed with method 1 (eigenvectors of X.T @ X) is %.5f and with method 2 (right singular vectors of X) is %.5f.\" % (time11, time21))\n",
    "print(\"For dimension = 3, the time elapsed with method 1 (eigenvectors of X.T @ X) is %.5f and with method 2 (right singular vectors of X) is %.5f.\" % (time12, time22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 is slightly slower if the number of dimensions n=2, and slighly faster if n=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0        8.0         307.0       130.0  3504.0          12.0   \n",
       "1    15.0        8.0         350.0       165.0  3693.0          11.5   \n",
       "2    18.0        8.0         318.0       150.0  3436.0          11.0   \n",
       "3    16.0        8.0         304.0       150.0  3433.0          12.0   \n",
       "4    17.0        8.0         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "401  27.0        4.0         140.0        86.0  2790.0          15.6   \n",
       "402  44.0        4.0          97.0        52.0  2130.0          24.6   \n",
       "403  32.0        4.0         135.0        84.0  2295.0          11.6   \n",
       "404  28.0        4.0         120.0        79.0  2625.0          18.6   \n",
       "405  31.0        4.0         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin                   car name  \n",
       "0          70.0     1.0  chevrolet chevelle malibu  \n",
       "1          70.0     1.0          buick skylark 320  \n",
       "2          70.0     1.0         plymouth satellite  \n",
       "3          70.0     1.0              amc rebel sst  \n",
       "4          70.0     1.0                ford torino  \n",
       "..          ...     ...                        ...  \n",
       "401        82.0     1.0            ford mustang gl  \n",
       "402        82.0     2.0                  vw pickup  \n",
       "403        82.0     1.0              dodge rampage  \n",
       "404        82.0     1.0                ford ranger  \n",
       "405        82.0     1.0                 chevy s-10  \n",
       "\n",
       "[406 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('auto-mpg.data-original', header=None, delim_whitespace=True,\n",
    "            names=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
    "                   'acceleration', 'model year', 'origin', 'car name'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders       float64\n",
       "displacement    float64\n",
       "horsepower      float64\n",
       "weight          float64\n",
       "acceleration    float64\n",
       "model year      float64\n",
       "origin          float64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all columns of interest have dtype float64, we can confidently say that there is no exotic string encoding for NaNs. <br>\n",
    "NaNs could therefore be exotically encoded with floats (e.g. 999.99), so we use df.describe to spot \"outliers\", but cannot see any irrational values (e.g. negative values) <br>\n",
    "Therefore, we should identify NaNs with the traditional df.isna() <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>398.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.514573</td>\n",
       "      <td>5.475369</td>\n",
       "      <td>194.779557</td>\n",
       "      <td>105.082500</td>\n",
       "      <td>2979.413793</td>\n",
       "      <td>15.519704</td>\n",
       "      <td>75.921182</td>\n",
       "      <td>1.568966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.815984</td>\n",
       "      <td>1.712160</td>\n",
       "      <td>104.922458</td>\n",
       "      <td>38.768779</td>\n",
       "      <td>847.004328</td>\n",
       "      <td>2.803359</td>\n",
       "      <td>3.748737</td>\n",
       "      <td>0.797479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1613.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>75.750000</td>\n",
       "      <td>2226.500000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>2822.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3618.250000</td>\n",
       "      <td>17.175000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement  horsepower       weight  \\\n",
       "count  398.000000  406.000000    406.000000  400.000000   406.000000   \n",
       "mean    23.514573    5.475369    194.779557  105.082500  2979.413793   \n",
       "std      7.815984    1.712160    104.922458   38.768779   847.004328   \n",
       "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
       "25%     17.500000    4.000000    105.000000   75.750000  2226.500000   \n",
       "50%     23.000000    4.000000    151.000000   95.000000  2822.500000   \n",
       "75%     29.000000    8.000000    302.000000  130.000000  3618.250000   \n",
       "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
       "\n",
       "       acceleration  model year      origin  \n",
       "count    406.000000  406.000000  406.000000  \n",
       "mean      15.519704   75.921182    1.568966  \n",
       "std        2.803359    3.748737    0.797479  \n",
       "min        8.000000   70.000000    1.000000  \n",
       "25%       13.700000   73.000000    1.000000  \n",
       "50%       15.500000   76.000000    1.000000  \n",
       "75%       17.175000   79.000000    2.000000  \n",
       "max       24.800000   82.000000    3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             8\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      6\n",
       "weight          0\n",
       "acceleration    0\n",
       "model year      0\n",
       "origin          0\n",
       "car name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "model year      0\n",
       "origin          0\n",
       "car name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('car name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0        8.0         307.0       130.0  3504.0          12.0   \n",
       "1    15.0        8.0         350.0       165.0  3693.0          11.5   \n",
       "2    18.0        8.0         318.0       150.0  3436.0          11.0   \n",
       "3    16.0        8.0         304.0       150.0  3433.0          12.0   \n",
       "4    17.0        8.0         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "387  27.0        4.0         140.0        86.0  2790.0          15.6   \n",
       "388  44.0        4.0          97.0        52.0  2130.0          24.6   \n",
       "389  32.0        4.0         135.0        84.0  2295.0          11.6   \n",
       "390  28.0        4.0         120.0        79.0  2625.0          18.6   \n",
       "391  31.0        4.0         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin  \n",
       "0          70.0     1.0  \n",
       "1          70.0     1.0  \n",
       "2          70.0     1.0  \n",
       "3          70.0     1.0  \n",
       "4          70.0     1.0  \n",
       "..          ...     ...  \n",
       "387        82.0     1.0  \n",
       "388        82.0     2.0  \n",
       "389        82.0     1.0  \n",
       "390        82.0     1.0  \n",
       "391        82.0     1.0  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Add two or three binary features to meaningfully encode the three origins ('origin' feature, for which, initially, 1 stands for USA, 2 for Europe and 3 for Japan) 3\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods are possible. 1) pd.get_dummies 2) Scikit Learn OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0        8.0         307.0       130.0  3504.0          12.0   \n",
       "1    15.0        8.0         350.0       165.0  3693.0          11.5   \n",
       "2    18.0        8.0         318.0       150.0  3436.0          11.0   \n",
       "3    16.0        8.0         304.0       150.0  3433.0          12.0   \n",
       "4    17.0        8.0         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "387  27.0        4.0         140.0        86.0  2790.0          15.6   \n",
       "388  44.0        4.0          97.0        52.0  2130.0          24.6   \n",
       "389  32.0        4.0         135.0        84.0  2295.0          11.6   \n",
       "390  28.0        4.0         120.0        79.0  2625.0          18.6   \n",
       "391  31.0        4.0         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin  \n",
       "0          70.0     USA  \n",
       "1          70.0     USA  \n",
       "2          70.0     USA  \n",
       "3          70.0     USA  \n",
       "4          70.0     USA  \n",
       "..          ...     ...  \n",
       "387        82.0     USA  \n",
       "388        82.0  Europe  \n",
       "389        82.0     USA  \n",
       "390        82.0     USA  \n",
       "391        82.0     USA  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before employing either method, we add the info\n",
    "df['origin'].replace([1,2,3],['USA','Europe', 'Japan'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'origin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-93524b23a7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1st solution using pd.get_dummies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df = pd.concat([df,pd.get_dummies(df['origin'],prefix='country')]\n\u001b[0m\u001b[1;32m      3\u001b[0m                ,axis=1).drop(['origin'],axis=1)\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# drop_first=True to drop one dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin'"
     ]
    }
   ],
   "source": [
    "# 1st solution using pd.get_dummies\n",
    "df = pd.concat([df,pd.get_dummies(df['origin'],prefix='country')]\n",
    "               ,axis=1).drop(['origin'],axis=1)\n",
    "# drop_first=True to drop one dim\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin_Europe</th>\n",
       "      <th>origin_Japan</th>\n",
       "      <th>origin_USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0        8.0         307.0       130.0  3504.0          12.0   \n",
       "1    15.0        8.0         350.0       165.0  3693.0          11.5   \n",
       "2    18.0        8.0         318.0       150.0  3436.0          11.0   \n",
       "3    16.0        8.0         304.0       150.0  3433.0          12.0   \n",
       "4    17.0        8.0         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "387  27.0        4.0         140.0        86.0  2790.0          15.6   \n",
       "388  44.0        4.0          97.0        52.0  2130.0          24.6   \n",
       "389  32.0        4.0         135.0        84.0  2295.0          11.6   \n",
       "390  28.0        4.0         120.0        79.0  2625.0          18.6   \n",
       "391  31.0        4.0         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin_Europe  origin_Japan  origin_USA  \n",
       "0          70.0            0.0           0.0         1.0  \n",
       "1          70.0            0.0           0.0         1.0  \n",
       "2          70.0            0.0           0.0         1.0  \n",
       "3          70.0            0.0           0.0         1.0  \n",
       "4          70.0            0.0           0.0         1.0  \n",
       "..          ...            ...           ...         ...  \n",
       "387        82.0            0.0           0.0         1.0  \n",
       "388        82.0            1.0           0.0         0.0  \n",
       "389        82.0            0.0           0.0         1.0  \n",
       "390        82.0            0.0           0.0         1.0  \n",
       "391        82.0            0.0           0.0         1.0  \n",
       "\n",
       "[392 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd solution using Sklearn OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df[['origin']]).toarray())\n",
    "enc_df.columns = enc.get_feature_names(['origin'])\n",
    "df = df.join(enc_df)\n",
    "df.drop('origin', axis=1, inplace=True)\n",
    "df\n",
    "# Can we put all of that into a pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB. We tried to add the OneHotEncoding to the pipeline (to use it in the last question), but we cannot easily rename the columns and drop the original \"origin\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) Select (manually) 9 rows of the dataset such that all 3 origins are represented, and model\n",
    "year is not constant. Get the least-squares estimator θˆ (with intercept) the prediction vector\n",
    "yˆ, considering only these 9 lines. What do you observe ? Why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we add part of the pipeline here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates('model year').sample(9).reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple linear regression with Scikit learn\n",
    "X = df2.drop('mpg',axis=1)\n",
    "y = df2.mpg\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "theta_hat = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "y_hat = X @ theta_hat + intercept \n",
    "y_hat\n",
    "\n",
    "print(theta_hat, intercept, y_hat, reg.score(X,y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we change the sample, we see that the weights are different - we even\n",
    "sometimes get illogical weights (e.g. a positive weight for the \"weight\" feature, which \n",
    "means that the heavier the car, the higher the mpg, (and the less the car \"consumes\" fuel)) <br>\n",
    "We can see that the r2 score is 1 (y_hat = y), wich might show that we are \"overfitting\"\n",
    "the training set <br>\n",
    "Therefore, we cannot safely extrapolate those weights to new\n",
    "data because our training set is too small <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) Now, get the least-squares estimator θˆ and the prediction vector yˆ (with intercept) over the\n",
    "whole dataset, after performing scaling/centering (the columns must have unit standard\n",
    "deviation and be zero mean). Which variables seem to best explain gasoline consumption\n",
    "according to your model ? Why wouldn’t this answer make sense if the columns were not\n",
    "normalized ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('mpg',axis=1).values\n",
    "y = df.mpg  \n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('scaler', StandardScaler(copy=False)), ('regression', LinearRegression())])\n",
    "pipeline.fit(X, y)\n",
    "reg = pipeline.named_steps['regression']\n",
    "theta_hat = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "print(theta_hat, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get r2 = 0.82, i.e. 82% of the var of the mpg can be explained by our weights.\n",
    "Weight is the most important feature. If the columns were not normalized, this would\n",
    "not make sense because the scale of weight is much higher than the other features\n",
    "and we would suspect the influence of weight to be overestimated.\n",
    "Here, having scaled the features, we can confidently say that weight is an\n",
    "important features, intependently of the range of values it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = X @ theta_hat + intercept \n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = y - y_hat\n",
    "r_sq_norm = LA.norm(r)**2\n",
    "r_sq_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn_bar = np.mean(y)\n",
    "yn_bar_vect = yn_bar * np.ones(len(y))\n",
    "yn_bar_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = LA.norm(y - yn_bar_vect)**2\n",
    "two = r_sq_norm + LA.norm(y_hat - yn_bar_vect)**2\n",
    "print(one, two)\n",
    "np.isclose(one, two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(np.array([[6, 225, 100, 3233, 15.4, 117, 0, 0, 1]]), \n",
    "                      columns=['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "                   'acceleration', 'model year', 'country_Europe', 'country_Japan', 'country_USA'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking the result\n",
    "y_hat = X_test.values @ theta_hat + intercept\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53.1 MPG seems very high, indeed higher than the maximum (46.6), which means that the consumption is very low. <br>\n",
    "In our original model, the model year have a weight of 2.86, which is the highest weight, which means that the more recent the car, the higher the mpg (and the less it consumes fuel) <br>\n",
    "Here, we get a very high mpg because we are extrapolating the weights with model year 117, which is much bigger than what we had in our training data. <br>\n",
    "It would be interesting to make further analysis to understand if this linear relation is still true 35 years after the training data (it could have been exponential due to hybrid cars for instance?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
